{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This model here is trained on 4 selected weather stations to predict one given weather station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and converting to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import datetime\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar intensity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load initial data\n",
    "hourly_sun_intensity = pd.read_excel('2-10_21_524-2 Andmed.xlsx', sheet_name = 'tunni sum.kiirgus', header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update column names by shortening them and converting to English\n",
    "newColumnNames = dict()\n",
    "newColumnNames[\"Aasta\"] = \"y\"\n",
    "newColumnNames[\"Kuu\"] = \"m\"\n",
    "newColumnNames[\"Päaev\"] = \"d\"\n",
    "newColumnNames[\"Kell (UTC)\"] = \"time\"\n",
    "for columnName in hourly_sun_intensity.columns:\n",
    "    if \"kiirgus\" in columnName:\n",
    "        newColumnNames[columnName] = \"solar_\"+columnName.replace(\" summaarne kiirgus, W/m²\", \"\")\n",
    "#newColumnNames = [\"y\", \"m\", \"d\", \"time\"]+[\"solar_\"+columnName.replace(\" summaarne kiirgus, W/m²\", \"\") for columnName in hourly_sun_intensity.columns if \"kiirgus\" in columnName]\n",
    "hourly_sun_intensity = hourly_sun_intensity.rename(columns=newColumnNames)\n",
    "#hourly_sun_intensity.columns = newColumnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some weather stations have changed locations over time, as the differences between their locations are rather small (less than 8 km)\n",
    "# We at first do not make separation between them\n",
    "\n",
    "def join_columns(c1, c2, nc, df, column_id): # Function for joining columns, where an area has two weather measuring points\n",
    "    data = []\n",
    "    cs = [c1, c2]\n",
    "    for i, rows in df[cs].iterrows():\n",
    "        if (pd.isna(rows[0]) == True) & (pd.isna(rows[1]) == False):\n",
    "            data.append(round(rows[1], 2))\n",
    "        elif (pd.isna(rows[0]) == False) & (pd.isna(rows[1]) == True):\n",
    "            data.append(round(rows[0], 2))\n",
    "        elif (pd.isna(rows[0]) == False) & (pd.isna(rows[1]) == False):\n",
    "            data.append(round(rows.mean(), 2))\n",
    "        elif (pd.isna(rows[0]) == True) & (pd.isna(rows[1]) == True):\n",
    "            data.append(rows[0])\n",
    "\n",
    "    df = df.drop(columns = [c1, c2])\n",
    "    df.insert(column_id, nc, data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge columns, which are due to weather station moving\n",
    "hourly_sun_intensity = join_columns('solar_Narva', 'solar_Narva-Jõesuu', 'solar_Narva', hourly_sun_intensity, 4)\n",
    "hourly_sun_intensity = join_columns('solar_Pärnu-Sauga', 'solar_Pärnu', 'solar_Pärnu', hourly_sun_intensity, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where some value is missing\n",
    "hourly_sun_intensity = hourly_sun_intensity.dropna()\n",
    "#If value is -1 it corresponds to night, set it to 0\n",
    "hourly_sun_intensity = hourly_sun_intensity.replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift the times -X minutes to facilitate predicting future solar intensity from existing\n",
    "def shiftDateTime(df, numberOfHours):\n",
    "    dateTimes = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        dateTimes+=[datetime.datetime.combine(datetime.date(row.y, row.m, row.d), row.time)+datetime.timedelta(hours=numberOfHours)]\n",
    "    df2 = copy.deepcopy(df)\n",
    "    df2[\"y\"] = [date.year for date in dateTimes]\n",
    "    df2[\"m\"] = [date.month for date in dateTimes]\n",
    "    df2[\"d\"] = [date.day for date in dateTimes]\n",
    "    df2[\"time\"] = [date.time() for date in dateTimes]\n",
    "    \n",
    "    return df2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_sun_intensity_Shifted = shiftDateTime(hourly_sun_intensity, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from different weather stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locations\n",
    "\n",
    "\n",
    "Tallinn-Harku\n",
    "Laius: N 59°23´53´´\n",
    "Pikkus: E 24°36´10´´\n",
    "Decimal\n",
    "Lat: 59.398055\n",
    "Long: 24.602778\n",
    "\n",
    "\n",
    "Haapsalu meteoroloogiajaam\n",
    "Laius N 58°56´40´´\n",
    "Pikkus E 23°33´18´´\n",
    "Decimal\n",
    "Lat: 58.944444\n",
    "Long: 23.555\n",
    "\n",
    "Narva\n",
    "Laius: N 59°23´22´´\n",
    "Pikkus: E 28°06´33´´\n",
    "Decimal\n",
    "Lat: 59.389444\n",
    "Long: 28.109167\n",
    "\n",
    "Pärnu\n",
    "Laius: N 58°23´4,44´´\n",
    "Pikkus: E 24°29´6,71´´\n",
    "Decimal\n",
    "Lat: 58.384556\n",
    "Long: 24.485197\n",
    "\n",
    "Roomassaare\n",
    "Laius: N 58°13’05”\n",
    "Pikkus: E 22°30’23”\n",
    "Decimal\n",
    "Lat: 58.218056 \n",
    "Long: 22.506389 \n",
    "\n",
    "Tartu-Tõravere meteoroloogiajaam\n",
    "Laius: N 58°15´51´´\n",
    "Pikkus: E 26°27´41´\n",
    "Decimal\n",
    "Lat: 58.264167\n",
    "Long: 26.461389\n",
    "\n",
    "Tiirikoja järvejaam\n",
    "Laius: N 58°51´55´´\n",
    "Pikkus: E 26°57´08´´\n",
    "Decimal\n",
    "Lat: 58.865278\n",
    "Long: 26.952222\n",
    "\n",
    "Vilsandi rannikujaam\n",
    "Laius: N 58°22´58”\n",
    "Pikkus: E 21°48´51”\n",
    "Deciaml\n",
    "Lat: 58.382778\n",
    "Long: 21.814167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_coordinates = dict()\n",
    "weather_station_coordinates[\"tallinn\"] = [59.398055, 24.602778]\n",
    "weather_station_coordinates[\"haapsalu\"] = [58.944444, 23.555]\n",
    "weather_station_coordinates[\"narva\"] = [59.389444, 28.109167]\n",
    "weather_station_coordinates[\"parnu\"] = [59.389444, 28.109167]\n",
    "weather_station_coordinates[\"roomassaare\"] = [58.218056, 22.506389]\n",
    "weather_station_coordinates[\"tartu\"] = [58.264167, 26.461389]\n",
    "weather_station_coordinates[\"tiirikoja\"] = [58.865278, 26.952222]\n",
    "weather_station_coordinates[\"vilsandi\"] = [58.382778, 21.814167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedColumns = [\"Aasta\", \"Kuu\", \"Päev\", \"Kell (UTC)\", \"Õhutemperatuur °C\",\"Suhteline õhuniiskus %\", \"10 minuti keskmine tuule kiirus m/s\", \"10 minuti keskmine tuule suund\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update column names by shortening them and converting to English\n",
    "\n",
    "def updateColumnNames(df, location):\n",
    "    newColumnNames = dict()\n",
    "    newColumnNames[\"Aasta\"] = \"y\"\n",
    "    newColumnNames[\"Kuu\"] = \"m\"\n",
    "    newColumnNames[\"Päev\"] = \"d\"\n",
    "    newColumnNames[\"Kell (UTC)\"] = \"time\"\n",
    "    newColumnNames[\"Õhutemperatuur °C\"] = f\"temp_{location}\"\n",
    "    newColumnNames[\"10 minuti keskmine tuule kiirus m/s\"] = f\"wind_speed_{location}\"\n",
    "    newColumnNames[\"Õhurõhk jaama kõrgusel hPa\"] = f\"pressure_{location}\"\n",
    "    newColumnNames[\"Suhteline õhuniiskus %\"] = f\"rel_humidity_{location}\"\n",
    "    newColumnNames[\"10 minuti keskmine tuule suund\"] = f\"wind_dir_{location}\"\n",
    "    df = df.rename(columns=newColumnNames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFromXlsx(filename, columns, location):\n",
    "    #Load xlsx\n",
    "    df = pd.read_excel(filename, header = 1)\n",
    "    df = df[columns]\n",
    "    #Drop rows where data is missing\n",
    "    #df = df.dropna()\n",
    "    #Update column names for clarity\n",
    "    df = updateColumnNames(df, location)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Tallinn\n",
    "data_tallinn = getFromXlsx(\"./data/Tallinn-Harku_2004-2020.xlsx\", selectedColumns, \"tallinn\")\n",
    "#data_tallinn[\"lat_tallinn\"] = len(data_tallinn)*[weather_station_coordinates[\"tallinn\"][0]]\n",
    "#data_tallinn[\"long_tallinn\"] = len(data_tallinn)*[weather_station_coordinates[\"tallinn\"][1]]\n",
    "#Get Roomassaare\n",
    "data_roomassaare = getFromXlsx(\"./data/Roomassaare_2008-2020.xlsx\", selectedColumns, \"roomassaare\")\n",
    "#data_roomassaare[\"lat_roomassaare\"] = len(data_roomassaare)*[weather_station_coordinates[\"roomassaare\"][0]]\n",
    "#data_roomassaare[\"long_roomassaare\"] = len(data_roomassaare)*[weather_station_coordinates[\"roomassaare\"][1]]\n",
    "#Merge tables\n",
    "data_weather = data_tallinn.merge(data_roomassaare, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Vilsandi\n",
    "data_vilsandi = getFromXlsx(\"./data/Vilsandi_2004-2020.xlsx\", selectedColumns, \"vilsandi\")\n",
    "#data_vilsandi[\"lat_vilsandi\"] = len(data_vilsandi)*[weather_station_coordinates[\"vilsandi\"][0]]\n",
    "#data_vilsandi[\"long_vilsandi\"] = len(data_vilsandi)*[weather_station_coordinates[\"vilsandi\"][1]]\n",
    "#Merge tables\n",
    "data_weather = data_weather.merge(data_vilsandi, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get Parnu\n",
    "#data_parnu1 = getFromXlsx(\"./data/Parnu-Sauga_01.12.2004-31.03.2019.xlsx\", selectedColumns, \"parnu\")\n",
    "#data_parnu2 = getFromXlsx(\"./data/Parnu_01.04.2019-2020.xlsx\", selectedColumns, \"parnu\")\n",
    "#data_parnu = data_parnu1.append(data_parnu2)\n",
    "\n",
    "##Merge tables\n",
    "#data_weather = data_weather.merge(data_parnu, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Tartu = getFromXlsx(\"./data/Tartu-Toravere_2004-2020.xlsx\", selectedColumns, \"tartu\")\n",
    "#data_Tartu[\"lat_tartu\"] = len(data_Tartu)*[weather_station_coordinates[\"tartu\"][0]]\n",
    "#data_Tartu[\"long_tartu\"] = len(data_Tartu)*[weather_station_coordinates[\"tartu\"][1]]\n",
    "#Merge tables\n",
    "\n",
    "data_weather = data_weather.merge(data_Tartu, how='left', on=[\"y\", \"m\", \"d\", \"time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Narva = getFromXlsx(\"./data/Narva_19.12.2013-2020.xlsx\", selectedColumns, \"narva\")\n",
    "data_weather = data_weather.merge(data_Narva, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once again drop all rows where some row is missing\n",
    "data_weather = data_weather.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join weather and solar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_solar_weather = hourly_sun_intensity_Shifted.merge(data_weather, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = []\n",
    "for i in range(len(data_solar_weather)):\n",
    "    hours+=[data_solar_weather.iloc[i].time.hour]\n",
    "data_solar_weather[\"h\"] = hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_solar_weather = data_solar_weather.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'm', 'd', 'time', 'solar_Narva', 'solar_Pärnu', 'solar_Haapsalu',\n",
       "       'solar_Tallinn-Harku', 'solar_Roomassaare', 'solar_Tartu-Tõravere',\n",
       "       'solar_Tiirikoja', 'solar_Vilsandi', 'temp_tallinn',\n",
       "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn',\n",
       "       'temp_roomassaare', 'rel_humidity_roomassaare',\n",
       "       'wind_speed_roomassaare', 'wind_dir_roomassaare', 'temp_vilsandi',\n",
       "       'rel_humidity_vilsandi', 'wind_speed_vilsandi', 'wind_dir_vilsandi',\n",
       "       'temp_tartu', 'rel_humidity_tartu', 'wind_speed_tartu',\n",
       "       'wind_dir_tartu', 'temp_narva', 'rel_humidity_narva',\n",
       "       'wind_speed_narva', 'wind_dir_narva', 'h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_solar_weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, predict Tallinn using Tallinn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn']]\n",
    "\n",
    "y = data_solar_weather[['solar_Tallinn-Harku']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.12577897000247"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# squared = False returns RMSE, otherwise MSE\n",
    "mean_squared_error(y_test, dtr.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.01107241412734"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.84158218583287"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2, predict Pärnu using Talinn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.23589459344848"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# squared = False returns RMSE, otherwise MSE\n",
    "mean_squared_error(y_test, dtr.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.36021142195774"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.9543162945638"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 other stations, predict Pärnu, different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Stations Tartu, Tallinn, Roomassaare, Vilsandi, predict Pärnu\n",
    "dtr 96.26316991627043\n",
    "rf 66.69709972042308\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'm', 'd', 'time', 'solar_Narva', 'solar_Pärnu', 'solar_Haapsalu',\n",
       "       'solar_Tallinn-Harku', 'solar_Roomassaare', 'solar_Tartu-Tõravere',\n",
       "       'solar_Tiirikoja', 'solar_Vilsandi', 'temp_tallinn',\n",
       "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn',\n",
       "       'temp_roomassaare', 'rel_humidity_roomassaare',\n",
       "       'wind_speed_roomassaare', 'wind_dir_roomassaare', 'temp_vilsandi',\n",
       "       'rel_humidity_vilsandi', 'wind_speed_vilsandi', 'wind_dir_vilsandi',\n",
       "       'temp_tartu', 'rel_humidity_tartu', 'wind_speed_tartu',\n",
       "       'wind_dir_tartu', 'temp_narva', 'rel_humidity_narva',\n",
       "       'wind_speed_narva', 'wind_dir_narva', 'h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_solar_weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn',\n",
    "       'temp_roomassaare', 'rel_humidity_roomassaare',\n",
    "       'wind_speed_roomassaare', 'wind_dir_roomassaare', 'temp_vilsandi',\n",
    "       'rel_humidity_vilsandi', 'wind_speed_vilsandi', 'wind_dir_vilsandi',\n",
    "       'temp_tartu', 'rel_humidity_tartu', 'wind_speed_tartu',\n",
    "       'wind_dir_tartu']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# squared = False returns RMSE, otherwise MSE\n",
    "mean_squared_error(y_test, dtr.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5 Stations Tartu, Tallinn, Roomassaare, Vilsandi, Narva, predict Pärnu\n",
    "dtr \n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.30923244650441"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, dtr.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.99407415307772"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "############### Random Forest ##############################\n",
    "\n",
    "n_estimatorss = [100]\n",
    "max_depths=[20]\n",
    "min_samples_splits=[4,6,8,16]\n",
    "seeds = [1]\n",
    "results_df = pd.DataFrame(columns=['model',\"seed\",\"n_estimators\",\"max_depth\",\"min_samples_split\",'TrainError', 'ValError', 'deltaErrors'])\n",
    "for seed in seeds:\n",
    "    for n_estimator in n_estimatorss:\n",
    "        for max_d in max_depths:\n",
    "            for min_ss in min_samples_splits:\n",
    "                rf = RandomForestRegressor(criterion=\"squared_error\", n_estimators=n_estimator, max_depth=max_d, min_samples_split=min_ss, random_state=seed).fit(X_train, y_train)\n",
    "                trainError = mean_squared_error(y_train, rf.predict(X_train), squared = False)\n",
    "                valError = mean_squared_error(y_test, rf.predict(X_test), squared = False)\n",
    "                results_df = results_df.append({'model': 'RF',\"seed\":seed,\"n_estimators\":n_estimator,\"max_depth\":max_d,\"min_samples_split\":min_ss,\"TrainError\":trainError, 'ValError':valError, 'deltaErrors':abs(trainError-valError)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>30.873757</td>\n",
       "      <td>67.119425</td>\n",
       "      <td>36.245668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>33.273907</td>\n",
       "      <td>67.285888</td>\n",
       "      <td>34.011981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>35.777680</td>\n",
       "      <td>67.457766</td>\n",
       "      <td>31.680086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>44.046657</td>\n",
       "      <td>68.225880</td>\n",
       "      <td>24.179223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model seed n_estimators max_depth min_samples_split  TrainError   ValError  \\\n",
       "0    RF    1          100        20                 4   30.873757  67.119425   \n",
       "1    RF    1          100        20                 6   33.273907  67.285888   \n",
       "2    RF    1          100        20                 8   35.777680  67.457766   \n",
       "3    RF    1          100        20                16   44.046657  68.225880   \n",
       "\n",
       "   deltaErrors  \n",
       "0    36.245668  \n",
       "1    34.011981  \n",
       "2    31.680086  \n",
       "3    24.179223  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"ValError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>30.61484</td>\n",
       "      <td>66.889728</td>\n",
       "      <td>36.274888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model seed n_estimators max_depth min_samples_split  TrainError   ValError  \\\n",
       "0    RF    1          200        20                 4    30.61484  66.889728   \n",
       "\n",
       "   deltaErrors  \n",
       "0    36.274888  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"deltaErrors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>36.957563</td>\n",
       "      <td>74.915639</td>\n",
       "      <td>37.958076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>29.719276</td>\n",
       "      <td>74.211733</td>\n",
       "      <td>44.492457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model seed n_estimators max_depth min_samples_split  TrainError   ValError  \\\n",
       "5     RF    1          100        40                 8   36.957563  74.915639   \n",
       "8     RF    1          100        50                 8   36.956893  74.917349   \n",
       "14    RF    1          100        70                 8   36.956893  74.917349   \n",
       "11    RF    1          100        60                 8   36.956893  74.917349   \n",
       "17    RF    1          100        80                 8   36.956893  74.917349   \n",
       "..   ...  ...          ...       ...               ...         ...        ...   \n",
       "33    RF    1          200        80                 4   29.717919  74.207728   \n",
       "30    RF    1          200        70                 4   29.717919  74.207728   \n",
       "27    RF    1          200        60                 4   29.717919  74.207728   \n",
       "24    RF    1          200        50                 4   29.717919  74.207728   \n",
       "21    RF    1          200        40                 4   29.719276  74.211733   \n",
       "\n",
       "    deltaErrors  \n",
       "5     37.958076  \n",
       "8     37.960456  \n",
       "14    37.960456  \n",
       "11    37.960456  \n",
       "17    37.960456  \n",
       "..          ...  \n",
       "33    44.489809  \n",
       "30    44.489809  \n",
       "27    44.489809  \n",
       "24    44.489809  \n",
       "21    44.492457  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"deltaErrors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  \"Since version 1.0, \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingRegressor(max_depth=10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "gbr = HistGradientBoostingRegressor(max_iter=100, max_depth=10)\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Pärnu, use 4 stations, use only one type of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'temp_roomassaare', 'temp_vilsandi',\n",
    "       'temp_tartu']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.92307200732515"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, dtr.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.96527929643392"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.86844172490507"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h',\n",
    "       'rel_humidity_tallinn', 'rel_humidity_roomassaare',\n",
    "       'rel_humidity_vilsandi', 'rel_humidity_tartu']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.89287296065847"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)\n",
    "dtr.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, dtr.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.07701172527304"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of trying Stacking to see if it works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>d</th>\n",
       "      <th>time</th>\n",
       "      <th>solar_Narva</th>\n",
       "      <th>solar_Pärnu</th>\n",
       "      <th>solar_Haapsalu</th>\n",
       "      <th>solar_Tallinn-Harku</th>\n",
       "      <th>solar_Roomassaare</th>\n",
       "      <th>solar_Tartu-Tõravere</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_dir_vilsandi</th>\n",
       "      <th>temp_tartu</th>\n",
       "      <th>rel_humidity_tartu</th>\n",
       "      <th>wind_speed_tartu</th>\n",
       "      <th>wind_dir_tartu</th>\n",
       "      <th>temp_narva</th>\n",
       "      <th>rel_humidity_narva</th>\n",
       "      <th>wind_speed_narva</th>\n",
       "      <th>wind_dir_narva</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30116</th>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>231.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30117</th>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>229.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>216.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30118</th>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>203.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>217.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>209.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30119</th>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120</th>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>203.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>220.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88783</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>195.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88784</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>191.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88785</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>202.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88786</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>200.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88787</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>206.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58369 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y   m   d      time  solar_Narva  solar_Pärnu  solar_Haapsalu  \\\n",
       "30116  2013  12  20  13:00:00          0.0          1.0             0.0   \n",
       "30117  2013  12  20  14:00:00          0.0          0.0             0.0   \n",
       "30118  2013  12  20  15:00:00          0.0          0.0             0.0   \n",
       "30119  2013  12  20  16:00:00          0.0          0.0             0.0   \n",
       "30120  2013  12  20  17:00:00          0.0          0.0             0.0   \n",
       "...     ...  ..  ..       ...          ...          ...             ...   \n",
       "88783  2020  12  31  18:00:00          0.0          0.0             0.0   \n",
       "88784  2020  12  31  19:00:00          0.0          0.0             0.0   \n",
       "88785  2020  12  31  20:00:00          0.0          0.0             0.0   \n",
       "88786  2020  12  31  21:00:00          0.0          0.0             0.0   \n",
       "88787  2020  12  31  22:00:00          0.0          0.0             0.0   \n",
       "\n",
       "       solar_Tallinn-Harku  solar_Roomassaare  solar_Tartu-Tõravere  ...  \\\n",
       "30116                    3                2.0                     3  ...   \n",
       "30117                    0                0.0                     0  ...   \n",
       "30118                    0                0.0                     0  ...   \n",
       "30119                    0                0.0                     0  ...   \n",
       "30120                    0                0.0                     0  ...   \n",
       "...                    ...                ...                   ...  ...   \n",
       "88783                    0                0.0                     0  ...   \n",
       "88784                    0                0.0                     0  ...   \n",
       "88785                    0                0.0                     0  ...   \n",
       "88786                    0                0.0                     0  ...   \n",
       "88787                    0                0.0                     0  ...   \n",
       "\n",
       "       wind_dir_vilsandi  temp_tartu  rel_humidity_tartu  wind_speed_tartu  \\\n",
       "30116              242.0         2.2                97.0               2.3   \n",
       "30117              212.0         2.7                96.0               2.8   \n",
       "30118              203.0         2.8                95.0               2.2   \n",
       "30119              209.0         3.0                94.0               3.0   \n",
       "30120              220.0         3.1                94.0               2.9   \n",
       "...                  ...         ...                 ...               ...   \n",
       "88783              175.0         1.1                97.0               1.5   \n",
       "88784              181.0         1.1                93.0               1.1   \n",
       "88785              189.0         1.0                96.0               1.5   \n",
       "88786              189.0         0.8                95.0               1.4   \n",
       "88787              167.0         0.5                96.0               1.0   \n",
       "\n",
       "       wind_dir_tartu  temp_narva  rel_humidity_narva  wind_speed_narva  \\\n",
       "30116           210.0         2.0                95.0               5.7   \n",
       "30117           229.0         2.0                95.0               3.4   \n",
       "30118           217.0         2.7                92.0               3.3   \n",
       "30119           212.0         2.1                95.0               4.5   \n",
       "30120           203.0         2.1                92.0               6.4   \n",
       "...               ...         ...                 ...               ...   \n",
       "88783           210.0         0.8                99.0               2.7   \n",
       "88784           229.0         0.7                98.0               2.9   \n",
       "88785           224.0         0.8                98.0               2.7   \n",
       "88786           202.0         0.8                98.0               2.8   \n",
       "88787           196.0         0.9                97.0               1.9   \n",
       "\n",
       "       wind_dir_narva   h  \n",
       "30116           231.0  13  \n",
       "30117           216.0  14  \n",
       "30118           209.0  15  \n",
       "30119           214.0  16  \n",
       "30120           220.0  17  \n",
       "...               ...  ..  \n",
       "88783           195.0  18  \n",
       "88784           191.0  19  \n",
       "88785           202.0  20  \n",
       "88786           200.0  21  \n",
       "88787           206.0  22  \n",
       "\n",
       "[58369 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_solar_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature selection for one model \n",
    "\n",
    "# Defining forward selection algorithm \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def forward_selector(maxFeatureN, train_y, test_y, train_X, test_X, random_seed, cv_k, originalData, \n",
    "                     isPandas = False):\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    returnList = {\"maxFeatureN\": maxFeatureN}\n",
    "    \n",
    "    candFeatures = list(range(train_X.shape[1]))\n",
    "    selection = []\n",
    "    \n",
    "    for i in range(maxFeatureN):\n",
    "        errScores = []\n",
    "        \n",
    "        for c in candFeatures: \n",
    "            S = list(selection)\n",
    "            S.append(c)\n",
    "            \n",
    "            if isPandas: \n",
    "                train_X_S = train_X.iloc[:, S]\n",
    "            else:\n",
    "                train_X_S = train_X[:,S]\n",
    "\n",
    "            # fitting the model\n",
    "            dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "            err = np.mean(model_selection.cross_val_score(dtr, \n",
    "                                                                train_X_S, \n",
    "                                                                train_y, \n",
    "                                                                cv=cv_k, \n",
    "                                                                ))\n",
    "\n",
    "            errScores.append(err)\n",
    "    \n",
    "        bestIndex = np.argmin(errScores)\n",
    "        \n",
    "        #Update current best selection\n",
    "        selection.append(candFeatures[bestIndex])\n",
    "        del candFeatures[bestIndex]\n",
    "    \n",
    "    if isPandas:\n",
    "        train_X_S = train_X.iloc[:,selection]\n",
    "    else:\n",
    "        train_X_S = train_X[:,selection]\n",
    "    #print(train_X_S.shape)\n",
    "    if isPandas:\n",
    "        test_X_S = test_X.iloc[:,selection]\n",
    "    else:\n",
    "        test_X_S = test_X[:,selection]\n",
    "        \n",
    "    #print(test_X_S.shape)\n",
    "\n",
    "\n",
    "    #svmClassifier = sklearn.svm.LinearSVC()\n",
    "    dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "    dtr.fit(train_X_S, train_y)\n",
    "    \n",
    "    train_y_hat = dtr.predict(train_X_S)\n",
    "    test_y_hat = dtr.predict(test_X_S)\n",
    "    \n",
    "    returnList[\"featuresSelectedNumeric\"] = [selection]\n",
    "    returnList[\"trainErr\"] = mean_squared_error(train_y, train_y_hat, squared = False)\n",
    "    returnList[\"testErr\"] = mean_squared_error(test_y, test_y_hat, squared = False)\n",
    "\n",
    "    \n",
    "    return returnList\n",
    "    \n",
    "    \n",
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn',\n",
    "       'temp_roomassaare', 'rel_humidity_roomassaare',\n",
    "       'wind_speed_roomassaare', 'wind_dir_roomassaare', 'temp_vilsandi',\n",
    "       'rel_humidity_vilsandi', 'wind_speed_vilsandi', 'wind_dir_vilsandi',\n",
    "       'temp_tartu', 'rel_humidity_tartu', 'wind_speed_tartu',\n",
    "       'wind_dir_tartu']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)\n",
    "\n",
    "\n",
    "\n",
    "## Running the algorithm with stopping rules\n",
    "\n",
    "errResults = []\n",
    "for ii in (range (1,10,1)):\n",
    "    \n",
    "    result = forward_selector(ii, y_train, y_test, X_train_scaled, X_test_scaled, 1, 10, X)\n",
    "    errResults.append(result[\"trainErr\"])\n",
    "    print(\"For cardinality\", ii, \"Best features are: \", result[\"featuresSelectedNumeric\"])\n",
    "    print(\"Giving performance in train set of \", result[\"trainErr\"])\n",
    "    print(\"Giving performance in test set of \", result[\"testErr\"])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "## Finding best stes for different stopping rules\n",
    "\n",
    "## Test untill you see decline in performance\n",
    "\n",
    "best_untill_decline_cardinality = None\n",
    "for i in range(len(errResults)):\n",
    "    if i == len(errResults)-1:\n",
    "        break\n",
    "    elif errResults[i] > errResults[i+1]:\n",
    "        next\n",
    "    elif errResults[i] <= errResults[i+1]:\n",
    "        best_untill_decline = i+1\n",
    "        break\n",
    "        \n",
    "        \n",
    "    \n",
    "print(\"Best set up to a point where model performance on train data starts to decrease is at cardinality: \", \n",
    "      best_untill_decline)\n",
    "\n",
    "\n",
    "print(\"Best overall set is: \", (np.argmax(errResults)+1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
